[T1]
csv_file = T1.csv
#path_to_search = /proj/NIRAL/users/siyangj/myData/normal/T1
#filename_contains = 
#filename_not_contains = flip
spatial_window_size = (80,80,80)
pixdim = (1.0, 1.0, 1.0)
axcodes=(A, R, S)
interp_order = 3

[T2]
csv_file = T2.csv
#path_to_search = /proj/NIRAL/users/siyangj/myData/normal/T2
#filename_contains = 
#filename_not_contains = flip
spatial_window_size = (80, 80, 80)
pixdim = (1.0, 1.0, 1.0)
axcodes=(A, R, S)
interp_order = 3

[parcellation]
csv_file = parcellation.csv
#path_to_search = /proj/NIRAL/users/siyangj/myData/normal/seg
#filename_contains = 
#filename_not_contains = flip
spatial_window_size = (80, 80, 80)
pixdim = (1.0, 1.0, 1.0)
axcodes=(A, R, S)
interp_order = 0

[SYSTEM]
cuda_devices = ""
num_threads = 4
num_gpus = 4
model_dir = /proj/NIRAL/users/siyangj/model_09251402
loader = SimpleITK
dataset_split_file = data_split

[NETWORK]
name = my_nets.my_unet.my_UNet3D
activation_function = relu
batch_size = 2
decay = 5e-5
reg_type = L2

# volume level preprocessing
# volume_padding_size = (16,16,16)
# histogram normalisation
normalisation = True
histogram_ref_file = hist_ref.txt
norm_type = percentile
cutoff = (0.01, 0.99)
whitening = True
normalise_foreground_only=True
foreground_type = otsu_plus
multimod_foreground_type = and

queue_length = 32
window_sampling = uniform

[TRAINING]
## For the purpose of experiment, try small number of samples
sample_per_volume = 64
rotation_angle = (-10.0, 10.0)
#scaling_percentage = (-10.0, 10.0)
lr = 3e-5
random_flipping_axes = 0,1,2
loss_type = CrossEntropy
starting_iter = -1
save_every_n = 50
max_iter = 100000
max_checkpoints = 1000

do_elastic_deformation = True
# too large might contaminate data
deformation_sigma = 3
num_ctrl_points = 8
# smaller to make data cleaner
proportion_to_deform = 0.7

validation_every_n = 20
validation_max_iter = 1

exclude_fraction_for_validation = 0.1
exclude_fraction_for_inference = 0.1

[INFERENCE]
#border = (16, 16, 16)
inference_iter = -1
save_seg_dir = inference
output_interp_order = 2
spatial_window_size = (80, 80, 80)

############################ custom configuration sections
[SEGMENTATION]
image = (T1,T2)
label = parcellation
output_prob = False
## After normalisation, should only have 3 classes.
num_classes = 4
label_normalisation = True

[EVALUATION]
save_csv_dir = eval
evaluations = Dice,Jaccard,hausdorff95_distance
