{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/patch_real_multi_task_tune.ini as config file.\n",
      ">>> **Network**: UNet Late Fusion\n",
      ">>> STAGE 1 TRAINING <<<\n",
      ">>> New param value: aux1_weight = 0.0\n",
      ">>> MODEL CREATED\n",
      ">>> OPTIMIZER CREATED\n",
      ">>> TRAINING START\n",
      "**Training**: restore last checkpoint from:/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/snapshot_best\n",
      "INFO:tensorflow:Restoring parameters from /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/snapshot_best\n",
      ">>>EPOCH 1\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n",
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  3] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 1 Test: [0.797, 0.826, 0.812]\n",
      ">>> Generating data from [['/proj/NIRAL/users/siyangj/myData/min_normal/T1/2.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/2.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-2.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/3.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/3.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-3.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/7.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/7.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-7.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/4.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/4.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-4.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/5.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/5.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-5.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/6.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/6.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-6.nrrd']]\n",
      ">>> Finished **Preloading Data**\n",
      "[ Wed Mar  6 22:33:01 2019], Epoch: [   1], Training Main Loss: [0.308], Lr[0.00044000]\n",
      ">>> Generating data from [['/proj/NIRAL/users/siyangj/myData/min_normal/T1/8.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/8.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-8.nrrd']]\n",
      ">>> Finished **Preloading Data**\n",
      "[ Wed Mar  6 22:33:02 2019], Epoch: [   1], Validation Main Loss: [0.226]\n",
      ">>>EPOCH 2\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n",
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  0] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 2 Test: [0.799, 0.832, 0.822]\n",
      "[ Wed Mar  6 22:33:21 2019], Epoch: [   2], Training Main Loss: [0.322], Lr[0.00044000]\n",
      "[ Wed Mar  6 22:33:22 2019], Epoch: [   2], Validation Main Loss: [0.208]\n",
      ">>>EPOCH 3\n",
      "Model saved in file: /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.0/snapshot_3\n",
      "Model saved in file: ['/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.0/snapshot_3']\n",
      ">> **Test evaluation** after training: restore model from iteration 2 at /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.0/snapshot_best\n",
      "INFO:tensorflow:Restoring parameters from /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.0/snapshot_best\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n",
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  0] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 2 Test: [0.794, 0.826, 0.821]\n",
      "[0.99508869 0.79420574 0.82625959 0.82095507]\n",
      ">>> New param value: aux1_weight = 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> MODEL CREATED\n",
      ">>> OPTIMIZER CREATED\n",
      ">>> TRAINING START\n",
      "**Training**: restore last checkpoint from:/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/snapshot_best\n",
      "INFO:tensorflow:Restoring parameters from /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/snapshot_best\n",
      ">>>EPOCH 1\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n",
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  1] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 1 Test: [0.797, 0.826, 0.812]\n",
      ">>> Generating data from [['/proj/NIRAL/users/siyangj/myData/min_normal/T1/2.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/2.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-2.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/3.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/3.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-3.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/7.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/7.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-7.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/4.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/4.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-4.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/5.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/5.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-5.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/6.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/6.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-6.nrrd']]\n",
      ">>> Finished **Preloading Data**\n",
      "[ Wed Mar  6 22:34:21 2019], Epoch: [   1], Training Main Loss: [0.308], Lr[0.00044000]\n",
      ">>> Generating data from [['/proj/NIRAL/users/siyangj/myData/min_normal/T1/8.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/8.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-8.nrrd']]\n",
      ">>> Finished **Preloading Data**\n",
      "[ Wed Mar  6 22:34:22 2019], Epoch: [   1], Validation Main Loss: [0.226]\n",
      ">>>EPOCH 2\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n",
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  0] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 2 Test: [0.799, 0.832, 0.822]\n",
      "[ Wed Mar  6 22:34:41 2019], Epoch: [   2], Training Main Loss: [0.322], Lr[0.00044000]\n",
      "[ Wed Mar  6 22:34:41 2019], Epoch: [   2], Validation Main Loss: [0.208]\n",
      ">>>EPOCH 3\n",
      "Model saved in file: /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.1/snapshot_3\n",
      "Model saved in file: ['/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.1/snapshot_3']\n",
      ">> **Test evaluation** after training: restore model from iteration 2 at /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.1/snapshot_best\n",
      "INFO:tensorflow:Restoring parameters from /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.1/snapshot_best\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n",
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  0] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 2 Test: [0.794, 0.826, 0.821]\n",
      "[0.99508972 0.79435311 0.82626488 0.82103986]\n",
      ">>> New param value: aux1_weight = 0.2\n",
      ">>> MODEL CREATED\n",
      ">>> OPTIMIZER CREATED\n",
      ">>> TRAINING START\n",
      "**Training**: restore last checkpoint from:/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/snapshot_best\n",
      "INFO:tensorflow:Restoring parameters from /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/snapshot_best\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>EPOCH 1\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n",
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  1] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 1 Test: [0.797, 0.826, 0.812]\n",
      ">>> Generating data from [['/proj/NIRAL/users/siyangj/myData/min_normal/T1/2.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/2.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-2.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/3.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/3.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-3.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/7.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/7.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-7.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/4.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/4.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-4.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/5.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/5.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-5.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/6.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/6.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-6.nrrd']]\n",
      ">>> Finished **Preloading Data**\n",
      "[ Wed Mar  6 22:35:39 2019], Epoch: [   1], Training Main Loss: [0.308], Lr[0.00044000]\n",
      ">>> Generating data from [['/proj/NIRAL/users/siyangj/myData/min_normal/T1/8.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/8.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-8.nrrd']]\n",
      ">>> Finished **Preloading Data**\n",
      "[ Wed Mar  6 22:35:40 2019], Epoch: [   1], Validation Main Loss: [0.226]\n",
      ">>>EPOCH 2\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n",
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  0] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 2 Test: [0.799, 0.832, 0.822]\n",
      "[ Wed Mar  6 22:36:00 2019], Epoch: [   2], Training Main Loss: [0.322], Lr[0.00044000]\n",
      "[ Wed Mar  6 22:36:00 2019], Epoch: [   2], Validation Main Loss: [0.208]\n",
      ">>>EPOCH 3\n",
      "Model saved in file: /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.2/snapshot_3\n",
      "Model saved in file: ['/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.2/snapshot_3']\n",
      ">> **Test evaluation** after training: restore model from iteration 2 at /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.2/snapshot_best\n",
      "INFO:tensorflow:Restoring parameters from /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.2/snapshot_best\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n",
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  0] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 2 Test: [0.794, 0.826, 0.821]\n",
      "[0.99508872 0.79444931 0.82627194 0.82110997]\n",
      ">>> New param value: aux1_weight = 0.30000000000000004\n",
      ">>> MODEL CREATED\n",
      ">>> OPTIMIZER CREATED\n",
      ">>> TRAINING START\n",
      "**Training**: restore last checkpoint from:/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/snapshot_best\n",
      "INFO:tensorflow:Restoring parameters from /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/snapshot_best\n",
      ">>>EPOCH 1\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  1] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 1 Test: [0.797, 0.826, 0.812]\n",
      ">>> Generating data from [['/proj/NIRAL/users/siyangj/myData/min_normal/T1/2.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/2.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-2.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-2.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/3.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/3.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-3.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-3.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/7.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/7.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-7.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-7.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/4.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/4.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-4.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-4.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/5.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/5.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-5.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-5.nrrd'], ['/proj/NIRAL/users/siyangj/myData/min_normal/T1/6.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/6.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-6.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-6.nrrd']]\n",
      ">>> Finished **Preloading Data**\n",
      "[ Wed Mar  6 22:36:58 2019], Epoch: [   1], Training Main Loss: [0.308], Lr[0.00044000]\n",
      ">>> Generating data from [['/proj/NIRAL/users/siyangj/myData/min_normal/T1/8.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/T2/8.nrrd', '/proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/prediction-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls1-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls2-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/distance_map_cls3-8.nrrd', '/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_pretrain1/error_map-8.nrrd']]\n",
      ">>> Finished **Preloading Data**\n",
      "[ Wed Mar  6 22:36:59 2019], Epoch: [   1], Validation Main Loss: [0.226]\n",
      ">>>EPOCH 2\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n",
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  0] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 2 Test: [0.799, 0.833, 0.822]\n",
      "[ Wed Mar  6 22:37:19 2019], Epoch: [   2], Training Main Loss: [0.322], Lr[0.00044000]\n",
      "[ Wed Mar  6 22:37:19 2019], Epoch: [   2], Validation Main Loss: [0.208]\n",
      ">>>EPOCH 3\n",
      "Model saved in file: /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.30000000000000004/snapshot_3\n",
      "Model saved in file: ['/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.30000000000000004/snapshot_3']\n",
      ">> **Test evaluation** after training: restore model from iteration 2 at /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.30000000000000004/snapshot_best\n",
      "INFO:tensorflow:Restoring parameters from /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/models/1/patch_real_multi_task_tune/aux1_weight-0.30000000000000004/snapshot_best\n",
      ">>> Begin evaluating with ground truth: /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1/1.nrrd\n",
      ">> begin predict nifit image: /proj/NIRAL/users/siyangj/myData/min_normal/T1/1.nrrd\n",
      ">> load nifti image finish..shape=(96, 112, 96)\n",
      "crop_index (0, 96, 0, 112, 0, 96)\n",
      ">> begin predict likelihood of each patch ..\n",
      ">> begin vote in overlapped patch..\n",
      "in vote: predictions.shape=(8, 1, 64, 64, 64, 4)\n",
      "predit patches of 1 image, cost [  0] seconds\n",
      "**>> img_data_t2  (96, 112, 96)\n",
      "final_segmentation  (96, 112, 96)\n",
      ">>> Epoch 2 Test: [0.795, 0.826, 0.821]\n",
      "[0.99508368 0.79454439 0.82628728 0.82121351]\n",
      ">>> New param value: aux1_weight = 0.4\n",
      ">>> MODEL CREATED\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1c4b6935061f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mprepare_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelete_train_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCreateTrainData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_test_in_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-1c4b6935061f>\u001b[0m in \u001b[0;36mCreateTrainData\u001b[0;34m(reset_graph)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'>>> MODEL CREATED'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mzero_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccum_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_minimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'>>> OPTIMIZER CREATED'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/proj/NIRAL/users/siyangj/ModelCodes/MyNet_1.0/model.pyc\u001b[0m in \u001b[0;36mcreate_optimizers\u001b[0;34m(train_loss)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mzero_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccum_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mgvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_opti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0maccum_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccum_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.pyc\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_OP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[1;32m    512\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_GRAPH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.pyc\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[0;32m--> 532\u001b[0;31m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.pyc\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, src_graph)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 701\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    702\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.pyc\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    394\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 701\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    702\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_grad.pyc\u001b[0m in \u001b[0;36m_BiasAddGrad\u001b[0;34m(op, received_grad)\u001b[0m\n\u001b[1;32m    293\u001b[0m   return (received_grad,\n\u001b[1;32m    294\u001b[0m           gen_nn_ops.bias_add_grad(\n\u001b[0;32m--> 295\u001b[0;31m               out_backprop=received_grad, data_format=data_format))\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36mbias_add_grad\u001b[0;34m(out_backprop, data_format, name)\u001b[0m\n\u001b[1;32m    762\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m    763\u001b[0m         \u001b[0;34m\"BiasAddGrad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0minput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m       \u001b[0;31m# Perform input type inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.argv = ['/usr/bin/python','/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/patch_real_multi_task_tune.ini']\n",
    "\n",
    "import config\n",
    "from config import FLAGS\n",
    "\n",
    "FLAGS.max_batch = 3\n",
    "FLAGS.overlap_add_num = 1\n",
    "\n",
    "from model import create_optimizers\n",
    "\n",
    "from train import train_model\n",
    "import random\n",
    "from generator import get_training_and_testing_generators\n",
    "from copy import deepcopy\n",
    "\n",
    "if 'bern' in FLAGS.network.lower():\n",
    "    if FLAGS.stage_1:\n",
    "        print \">>> **Network**: BernNet Stage 1\"\n",
    "        from BernNet import create_model_infant_seg as create_model\n",
    "    else:\n",
    "        print \">>> **Network**: BernNet Stage 2\"\n",
    "        from BernNet import create_model_infant_t1t2dm123_seg as create_model\n",
    "\n",
    "elif 'unet' in FLAGS.network.lower() or 'u-net' in FLAGS.network.lower():\n",
    "    if FLAGS.stage_1:\n",
    "        if 'early' in FLAGS.network.lower():\n",
    "            print \">>> **Network**: UNet Early Fusion\"\n",
    "            from UNet import create_UNet_early_fusion as create_model\n",
    "        else:\n",
    "            print \">>> **Network**: UNet Late Fusion\"\n",
    "            from UNet import create_UNet_late_fusion as create_model\n",
    "    else:\n",
    "        print 'Not yet finished'\n",
    "        sys.exit(0)\n",
    "\n",
    "def prepare_dirs(delete_train_dir=False):\n",
    "    # Create checkpoint dir (do not delete anything)\n",
    "    if not tf.gfile.Exists(FLAGS.checkpoint_dir):\n",
    "        tf.gfile.MakeDirs(FLAGS.checkpoint_dir)\n",
    "    \n",
    "    # Cleanup train dir\n",
    "    if delete_train_dir:\n",
    "        if tf.gfile.Exists(FLAGS.checkpoint_dir):\n",
    "            tf.gfile.DeleteRecursively(FLAGS.checkpoint_dir)\n",
    "        tf.gfile.MakeDirs(FLAGS.checkpoint_dir)\n",
    "\n",
    "def setup_tensorflow():\n",
    "    \n",
    "    config = tf.ConfigProto(log_device_placement=FLAGS.log_device_placement)\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    # Initialize rng with a deterministic seed\n",
    "    with sess.graph.as_default():\n",
    "        tf.set_random_seed(FLAGS.random_seed)\n",
    "        \n",
    "    random.seed(FLAGS.random_seed)\n",
    "    np.random.seed(FLAGS.random_seed)\n",
    "\n",
    "    tf.gfile.MkDir('%s/training_log' % (FLAGS.checkpoint_dir,))\n",
    "    tf.gfile.MkDir('%s/validation_log' % (FLAGS.checkpoint_dir,))\n",
    "    summary_writer = tf.summary.FileWriter('%s/training_log' % (FLAGS.checkpoint_dir,), sess.graph)\n",
    "    val_sum_writer = tf.summary.FileWriter('%s/validation_log' % (FLAGS.checkpoint_dir,), sess.graph)\n",
    "    \n",
    "    if FLAGS.show_test_in_training:\n",
    "        tf.gfile.MkDir('%s/test_log' % (FLAGS.checkpoint_dir,))\n",
    "        test_sum_writer = tf.summary.FileWriter('%s/test_log' % (FLAGS.checkpoint_dir,), sess.graph)\n",
    "        return sess, summary_writer, val_sum_writer, test_sum_writer\n",
    "\n",
    "    return sess, summary_writer, val_sum_writer\n",
    "\n",
    "class TrainData(object):\n",
    "    def __init__(self, dictionary):\n",
    "        self.__dict__.update(dictionary)\n",
    "\n",
    "def CreateTrainData(reset_graph=True):\n",
    "    if reset_graph:\n",
    "        tf.reset_default_graph()\n",
    "    \n",
    "    model_ret = create_model(train_phase=True)\n",
    "\n",
    "    (tf_t1_input, tf_t2_input, tf_label, \n",
    "            aux1_pred, aux2_pred, main_pred,\n",
    "            aux1_loss, aux2_loss, main_loss, \n",
    "            final_loss, gene_vars, main_possibility) = model_ret[:12]\n",
    "    if not FLAGS.stage_1:\n",
    "        tf_dm_input1, tf_dm_input2, tf_dm_input3 = model_ret[12:15]\n",
    "    if FLAGS.use_error_map:\n",
    "        tf_weight_main = model_ret[-1]\n",
    "\n",
    "    print '>>> MODEL CREATED'\n",
    "    zero_ops, accum_ops, train_minimize, learning_rate, global_step = create_optimizers(final_loss)\n",
    "    print '>>> OPTIMIZER CREATED'\n",
    "\n",
    "    train_data = TrainData(locals())\n",
    "    return train_data\n",
    "\n",
    "print '>>> STAGE %d TRAINING <<<' % (1 if FLAGS.stage_1 else 2)\n",
    "\n",
    "checkpoint_dir = FLAGS.checkpoint_dir\n",
    "STATS_LIST = []\n",
    "STATS_LIST_FILE = os.path.join(checkpoint_dir,'AuxWeightExperiment-aux2=%s.list'%FLAGS.aux2_weight)\n",
    "\n",
    "FLAGS.aux2_weight = 0.9\n",
    "\n",
    "param_name = 'aux1_weight'\n",
    "param_range = np.linspace(0,0.8,9)\n",
    "\n",
    "assert param_range is not None, 'Not implemented yet!'\n",
    "\n",
    "if param_range is not None:\n",
    "    for param in param_range:\n",
    "        \n",
    "        print '>>> New param value: %s = %s' % (param_name,str(param))\n",
    "        setattr(FLAGS,param_name,param)\n",
    "        FLAGS.checkpoint_dir = os.path.join(checkpoint_dir,'%s-%s'%(param_name,param))\n",
    "        if not os.path.exists(FLAGS.checkpoint_dir):\n",
    "            os.mkdir(FLAGS.checkpoint_dir)\n",
    "        prepare_dirs(delete_train_dir=False)\n",
    "        \n",
    "        train_data = CreateTrainData()\n",
    "\n",
    "        if FLAGS.show_test_in_training:\n",
    "            sess, summary_writer, val_sum_writer, test_sum_writer = setup_tensorflow()\n",
    "        else:\n",
    "            sess, summary_writer, val_sum_writer = setup_tensorflow()\n",
    "            \n",
    "        train_data.__dict__.update(locals())\n",
    "        print '>>> TRAINING START'\n",
    "        cur_stats = train_model(train_data)\n",
    "        with open(STATS_LIST_FILE,'a') as f:\n",
    "            f.write(str(param))\n",
    "            f.write(':  ')\n",
    "            f.write(np.array2string(np.asarray(cur_stats),separator=', '))\n",
    "            f.write('\\n')\n",
    "        STATS_LIST += [cur_stats,]\n",
    "\n",
    "    STATS_LIST = np.asarray(STATS_LIST)\n",
    "    best_index = STATS_LIST.mean(axis=1).argmax()\n",
    "    best_param = param_range[best_index]\n",
    "    best_stats = STATS_LIST[best_index,:]\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print STATS_LIST,best_param\n",
    "\n",
    "with open(STATS_LIST_FILE,'a') as f:\n",
    "    f.write('>>> Best param:  %f\\n'%best_param)\n",
    "    f.write('>>> Best stats:  ')\n",
    "    f.write(np.array2string(np.asarray(best_stats),separator=', '))\n",
    "    f.write('\\n')\n",
    "\n",
    "os.system('cp -r %s %s'%(os.path.join(checkpoint_dir,'%s-%s'%(param_name,best_param),'*'),checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['/usr/bin/python','/proj/NIRAL/users/siyangj/NewModels/model_0227_unet/patch_real_multi_task_tune.ini','0.9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('python Tune_MultiTask.py /proj/NIRAL/users/siyangj/NewModels/model_0227_unet/patch_real_multi_task_tune.ini 0.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
