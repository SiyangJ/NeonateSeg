[T1]
csv_file = T1.csv
#path_to_search = /proj/NIRAL/users/siyangj/myData/min_normal/T1
#filename_contains = 
#filename_not_contains = flip
spatial_window_size = (32, 32, 32)
pixdim = (1.0, 1.0, 1.0)
axcodes=(A, R, S)
interp_order = 3

[T2]
csv_file = T2.csv
#path_to_search = /proj/NIRAL/users/siyangj/myData/min_normal/T2
#filename_contains = 
#filename_not_contains = flip
spatial_window_size = (32, 32, 32)
pixdim = (1.0, 1.0, 1.0)
axcodes=(A, R, S)
interp_order = 3

[parcellation]
csv_file = parcellation.csv
#path_to_search = /proj/NIRAL/users/siyangj/myData/min_normal/seg_inf_1
#filename_contains = 
#filename_not_contains = flip
spatial_window_size = (32, 32, 32)
pixdim = (1.0, 1.0, 1.0)
axcodes=(A, R, S)
interp_order = 0

[SYSTEM]
cuda_devices = ""
num_threads = 2
num_gpus = 2
model_dir = /proj/NIRAL/users/siyangj/model_10210136
loader = SimpleITK
dataset_split_file = data_split

[NETWORK]
name = my_nets.my_unet_layer_2.my_unet_layer_2
activation_function = relu
batch_size = 2
decay = 5e-5
reg_type = L2

# volume level preprocessing
# volume_padding_size = (16,16,16)
# histogram normalisation
normalisation = True
histogram_ref_file = hist_ref.txt
norm_type = percentile
cutoff = (0.01, 0.99)
whitening = True
normalise_foreground_only=True
foreground_type = otsu_plus
multimod_foreground_type = and

queue_length = 32
window_sampling = uniform

keep_prob = 0.8

[TRAINING]
## For the purpose of experiment, try small number of samples
sample_per_volume = 300
rotation_angle = (-10.0, 10.0)
## Scaling will change the size of the image
scaling_percentage = (-5.0, 5.0)
lr = 2e-5
random_flipping_axes = 0,1,2
loss_type = CrossEntropy
starting_iter = 60000
save_every_n = 400
max_iter = 70000
max_checkpoints = 10000

do_elastic_deformation = True
# too large might contaminate data
deformation_sigma = 4
num_ctrl_points = 8
# smaller to make data cleaner
proportion_to_deform = 0.8

validation_every_n = 20
validation_max_iter = 1

exclude_fraction_for_validation = 0.1
exclude_fraction_for_inference = 0.1

[INFERENCE]
#border = (16, 16, 16)
inference_iter = 50000
save_seg_dir = inference_50000
output_interp_order = 2
spatial_window_size = (32, 32, 32)
dataset_to_infer = all

############################ custom configuration sections
[SEGMENTATION]
image = (T1,T2)
label = parcellation
output_prob = False
## After normalisation, should only have 3 classes.
num_classes = 4
label_normalisation = True

[EVALUATION]
save_csv_dir = eval_50000
evaluations = Dice,Jaccard,hausdorff95_distance
